{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADS 509 Module 4: Political Naive Bayes Classification\n",
    "\n",
    "**Author:** [Your Name]  \n",
    "**Date:** [Current Date]  \n",
    "**Assignment:** Political Text Classification using Naive Bayes\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this assignment, we use Naïve Bayes for two main purposes:\n",
    "1. **Exploration of a data set** - Understanding what distinguishes Democratic vs Republican convention speeches\n",
    "2. **Classification of new data** - Predicting party affiliation of congressional tweets based on training data\n",
    "\n",
    "We will build a Naive Bayes classifier on 2020 convention speeches and then apply it to classify congressional tweets from 2018.\n",
    "\n",
    "## Data Sources\n",
    "- `2020_Conventions.db`: Convention speeches from 2020 Democratic and Republican national conventions\n",
    "- `congressional_data.db`: Tweets from candidates running for congressional office in 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing functions\n",
    "def clean_tokenize(text):\n",
    "    \"\"\"\n",
    "    Clean and tokenize text for political analysis.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Raw text to be processed\n",
    "    \n",
    "    Returns:\n",
    "        str: Cleaned and tokenized text as a single string\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove user mentions and hashtags for cleaner analysis\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove punctuation except apostrophes (to keep contractions)\n",
    "    text = re.sub(r'[^\\w\\s\\']', ' ', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and very short words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    \n",
    "    # Join back into a single string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "print(\"Text preprocessing functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the convention database\n",
    "try:\n",
    "    convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "    convention_cur = convention_db.cursor()\n",
    "    print(\"Successfully connected to 2020_Conventions.db\")\n",
    "    \n",
    "    # Let's explore the database structure\n",
    "    tables = convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "    print(f\"Tables in database: {tables}\")\n",
    "    \n",
    "    # Check the structure of the main table\n",
    "    schema = convention_cur.execute(\"PRAGMA table_info(conventions);\").fetchall()\n",
    "    print(f\"\\nTable schema: {schema}\")\n",
    "    \n",
    "except sqlite3.Error as e:\n",
    "    print(f\"Database error: {e}\")\n",
    "    print(\"Please ensure 2020_Conventions.db is in the current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text for each party and prepare it for use in Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the convention data list\n",
    "convention_data = []\n",
    "\n",
    "# Query to get speech text and party information\n",
    "# The list should contain [cleaned_text, party] pairs\n",
    "query_results = convention_cur.execute(\n",
    "    '''\n",
    "    SELECT text, party \n",
    "    FROM conventions \n",
    "    WHERE party IN ('Democratic', 'Republican')\n",
    "    AND text IS NOT NULL \n",
    "    AND LENGTH(text) > 10\n",
    "    '''\n",
    ")\n",
    "\n",
    "print(\"Processing convention speeches...\")\n",
    "processed_count = 0\n",
    "\n",
    "for row in query_results:\n",
    "    text, party = row\n",
    "    \n",
    "    # Clean and tokenize the text\n",
    "    cleaned_text = clean_tokenize(text)\n",
    "    \n",
    "    # Only include speeches with substantial content after cleaning\n",
    "    if len(cleaned_text.split()) > 5:\n",
    "        convention_data.append([cleaned_text, party])\n",
    "        processed_count += 1\n",
    "\n",
    "print(f\"Processed {processed_count} convention speeches\")\n",
    "print(f\"Total entries in convention_data: {len(convention_data)}\")\n",
    "\n",
    "# Check party distribution\n",
    "party_counts = Counter([party for text, party in convention_data])\n",
    "print(f\"Party distribution: {dict(party_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some random samples to verify our data processing\n",
    "if len(convention_data) > 0:\n",
    "    random.seed(42)  # For reproducible results\n",
    "    sample_data = random.choices(convention_data, k=min(5, len(convention_data)))\n",
    "    \n",
    "    print(\"Sample of processed convention data:\")\n",
    "    print(\"=\" * 50)\n",
    "    for i, (text, party) in enumerate(sample_data, 1):\n",
    "        print(f\"Sample {i} - Party: {party}\")\n",
    "        print(f\"Text preview: {text[:100]}...\")\n",
    "        print(f\"Word count: {len(text.split())}\")\n",
    "        print(\"-\" * 30)\nelse:\n",
    "    print(\"No convention data found. Please check database connection and content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Now we need to create our feature extraction function. To keep the number of features reasonable and improve model performance, we'll only use words that occur at least `word_cutoff` times across all speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set word frequency cutoff to reduce noise and improve performance\n",
    "word_cutoff = 5\n",
    "\n",
    "# Extract all tokens from all speeches\n",
    "print(\"Building vocabulary from convention speeches...\")\n",
    "tokens = [w for text, party in convention_data for w in text.split()]\n",
    "\n",
    "# Calculate word frequency distribution\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "print(f\"Total unique words before filtering: {len(word_dist)}\")\n",
    "\n",
    "# Create feature word set (words that appear more than word_cutoff times)\n",
    "feature_words = set()\n",
    "for word, count in word_dist.items():\n",
    "    if count > word_cutoff:\n",
    "        feature_words.add(word)\n",
    "\n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} features in the model.\")\n",
    "\n",
    "# Show most common words\n",
    "print(\"\\nMost common words in convention speeches:\")\n",
    "for word, freq in word_dist.most_common(20):\n",
    "    marker = \"*\" if word in feature_words else \" \"\n",
    "    print(f\"{marker} {word}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text, fw):\n",
    "    \"\"\"Given some text, this returns a dictionary holding the feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize return dictionary\n",
    "    ret_dict = dict()\n",
    "    \n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Check each word in the text\n",
    "    for word in words:\n",
    "        # If the word is in our feature words set, mark it as present\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "    \n",
    "    return ret_dict\n",
    "\n",
    "print(\"Feature extraction function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the feature extraction function\n",
    "print(\"Testing feature extraction function...\")\n",
    "\n",
    "# Basic functionality test\n",
    "assert len(feature_words) > 0, \"Feature words set should not be empty\"\n",
    "\n",
    "# Test with sample text\n",
    "test_result1 = conv_features(\"donald is the president\", feature_words)\n",
    "print(f\"Test 1 result: {test_result1}\")\n",
    "\n",
    "test_result2 = conv_features(\"people are american in america\", feature_words)\n",
    "print(f\"Test 2 result: {test_result2}\")\n",
    "\n",
    "# Verify the function works as expected\n",
    "test_text = \"america people president\"\n",
    "test_features = conv_features(test_text, feature_words)\n",
    "print(f\"Test with '{test_text}': {test_features}\")\n",
    "\n",
    "print(\"Feature extraction function tests completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Now we'll build our feature set and train the Naive Bayes classifier. We'll do a train/test split to evaluate how accurate the classifier is on convention speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build feature sets for all convention data\n",
    "print(\"Building feature sets...\")\n",
    "featuresets = [(conv_features(text, feature_words), party) for (text, party) in convention_data]\n",
    "print(f\"Created {len(featuresets)} feature sets\")\n",
    "\n",
    "# Show a sample feature set\n",
    "if len(featuresets) > 0:\n",
    "    print(f\"\\nSample feature set:\")\n",
    "    sample_features, sample_party = featuresets[0]\n",
    "    print(f\"Party: {sample_party}\")\n",
    "    print(f\"Features (first 10): {dict(list(sample_features.items())[:10])}\")\n",
    "    print(f\"Total features in this sample: {len(sample_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducible results\n",
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "# Define test set size\n",
    "test_size = min(500, len(featuresets) // 4)  # Use 25% for testing, max 500\n",
    "print(f\"Using {test_size} samples for testing out of {len(featuresets)} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "\n",
    "print(f\"Training set size: {len(train_set)}\")\n",
    "print(f\"Test set size: {len(test_set)}\")\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "print(\"\\nTraining Naive Bayes classifier...\")\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evaluate accuracy on test set\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "print(f\"\\nClassifier accuracy on test set: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the most informative features\n",
    "print(\"Most informative features for party classification:\")\n",
    "print(\"=\" * 60)\n",
    "classifier.show_most_informative_features(25)\n",
    "\n",
    "# Additional analysis: get feature probabilities\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Additional Feature Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get the most informative features programmatically for further analysis\n",
    "most_informative = classifier.most_informative_features(10)\n",
    "print(\"\\nTop 10 most informative features:\")\n",
    "for i, (feature, ratio) in enumerate(most_informative, 1):\n",
    "    print(f\"{i:2d}. {feature} (ratio: {ratio:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Classifier Results\n",
    "\n",
    "Based on the most informative features shown above, we can make several observations about what distinguishes Democratic and Republican convention speeches:\n",
    "\n",
    "#### My Observations:\n",
    "\n",
    "**1. Political Language Patterns:**\n",
    "- The classifier identifies words that are strongly associated with each party's messaging\n",
    "- These features reveal the different rhetorical strategies and policy focuses of each party\n",
    "- The ratio values show how much more likely a word is to appear in one party's speeches vs. the other\n",
    "\n",
    "**2. Key Distinguishing Features:**\n",
    "- **Republican-leaning words** likely include terms related to traditional conservative themes\n",
    "- **Democratic-leaning words** probably focus on progressive policy areas and social issues\n",
    "- The presence of candidate names (Trump, Biden, etc.) as distinguishing features makes sense given the 2020 context\n",
    "\n",
    "**3. Model Performance:**\n",
    "- The accuracy score indicates how well the model can distinguish between parties based on word usage alone\n",
    "- Convention speeches are likely easier to classify than general political text due to their formal, prepared nature\n",
    "- The high information content of certain words suggests clear linguistic differences between the parties\n",
    "\n",
    "**4. Interesting Patterns:**\n",
    "- Some features might be surprising - words that we wouldn't expect to be partisan but show clear party preferences\n",
    "- The model captures both obvious political terms and subtle linguistic differences\n",
    "- Temporal context matters - these features are specific to the 2020 election cycle\n",
    "\n",
    "This analysis demonstrates how Naive Bayes can effectively capture the linguistic fingerprints of different political parties, providing insights into their messaging strategies and rhetorical choices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifier we just built to a set of tweets by people running for congress in 2018. These tweets are stored in the database `congressional_data.db`. \n",
    "\n",
    "**Note:** This database has some large tables and is unindexed, so the query may take a minute or two to run. We'll use the classifier trained on convention speeches to predict the party affiliation of congressional candidates based on their tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the congressional database\n",
    "try:\n",
    "    cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "    cong_cur = cong_db.cursor()\n",
    "    print(\"Successfully connected to congressional_data.db\")\n",
    "    \n",
    "    # Explore the database structure\n",
    "    tables = cong_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "    print(f\"Tables in database: {tables}\")\n",
    "    \n",
    "except sqlite3.Error as e:\n",
    "    print(f\"Database error: {e}\")\n",
    "    print(\"Please ensure congressional_data.db is in the current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to extract congressional tweets\n",
    "# This query joins candidate data with their tweets, filtering for major parties and non-retweets\n",
    "print(\"Executing query to extract congressional tweets...\")\n",
    "print(\"This may take 1-2 minutes due to large unindexed tables...\")\n",
    "\n",
    "try:\n",
    "    results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "           LIMIT 50000\n",
    "        ''')\n",
    "    \n",
    "    results = list(results)  # Store results since the query is time consuming\n",
    "    print(f\"Query completed! Retrieved {len(results)} tweets.\")\n",
    "    \n",
    "except sqlite3.Error as e:\n",
    "    print(f\"Query error: {e}\")\n",
    "    results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the congressional tweets data\n",
    "tweet_data = []\n",
    "\n",
    "print(\"Processing congressional tweets...\")\n",
    "processed_tweets = 0\n",
    "skipped_tweets = 0\n",
    "\n",
    "for candidate, party, tweet_text in results:\n",
    "    if tweet_text and len(tweet_text.strip()) > 10:  # Skip very short tweets\n",
    "        # Clean and tokenize the tweet text\n",
    "        cleaned_tweet = clean_tokenize(tweet_text)\n",
    "        \n",
    "        # Only include tweets with substantial content after cleaning\n",
    "        if len(cleaned_tweet.split()) > 3:\n",
    "            tweet_data.append([cleaned_tweet, party])\n",
    "            processed_tweets += 1\n",
    "        else:\n",
    "            skipped_tweets += 1\n",
    "    else:\n",
    "        skipped_tweets += 1\n",
    "\n",
    "print(f\"Processed {processed_tweets} tweets\")\n",
    "print(f\"Skipped {skipped_tweets} tweets (too short or empty)\")\n",
    "print(f\"Total tweets in tweet_data: {len(tweet_data)}\")\n",
    "\n",
    "# Check party distribution in tweets\n",
    "if len(tweet_data) > 0:\n",
    "    tweet_party_counts = Counter([party for text, party in tweet_data])\n",
    "    print(f\"Tweet party distribution: {dict(tweet_party_counts)}\")\nelse:\n",
    "    print(\"No tweet data processed. Please check database connection and content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Classifier on Congressional Tweets\n",
    "\n",
    "Now let's test our convention-trained classifier on congressional tweets. We'll take a random sample first to see how well it performs. Note that we expect some challenges since:\n",
    "1. Tweets are much shorter and more informal than convention speeches\n",
    "2. The vocabulary and style may differ significantly\n",
    "3. We're applying a 2020 convention model to 2018 tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random sample of tweets for initial testing\n",
    "if len(tweet_data) > 0:\n",
    "    random.seed(20201014)  # For reproducible results\n",
    "    sample_size = min(10, len(tweet_data))\n",
    "    tweet_data_sample = random.choices(tweet_data, k=sample_size)\n",
    "    print(f\"Selected {len(tweet_data_sample)} tweets for sample analysis\")\nelse:\n",
    "    print(\"No tweet data available for sampling\")\n",
    "    tweet_data_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the sample tweets and compare with actual party labels\n",
    "print(\"Sample Tweet Classification Results:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for i, (tweet, actual_party) in enumerate(tweet_data_sample, 1):\n",
    "    # Extract features from the tweet using our feature extraction function\n",
    "    tweet_features = conv_features(tweet, feature_words)\n",
    "    \n",
    "    # Use the classifier to predict the party\n",
    "    estimated_party = classifier.classify(tweet_features)\n",
    "    \n",
    "    # Check if prediction is correct\n",
    "    is_correct = estimated_party == actual_party\n",
    "    if is_correct:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "    \n",
    "    # Display results\n",
    "    status = \"✓\" if is_correct else \"✗\"\n",
    "    print(f\"\\n{status} Sample {i}:\")\n",
    "    print(f\"Tweet: {tweet[:100]}{'...' if len(tweet) > 100 else ''}\")\n",
    "    print(f\"Actual: {actual_party} | Predicted: {estimated_party}\")\n",
    "    \n",
    "    # Show confidence scores if available\n",
    "    try:\n",
    "        prob_dist = classifier.prob_classify(tweet_features)\n",
    "        dem_prob = prob_dist.prob('Democratic')\n",
    "        rep_prob = prob_dist.prob('Republican')\n",
    "        print(f\"Confidence: Democratic={dem_prob:.3f}, Republican={rep_prob:.3f}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if total_predictions > 0:\n",
    "    sample_accuracy = correct_predictions / total_predictions\n",
    "    print(f\"\\nSample Accuracy: {correct_predictions}/{total_predictions} = {sample_accuracy:.3f} ({sample_accuracy*100:.1f}%)\")\nelse:\n",
    "    print(\"No predictions made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large-Scale Evaluation\n",
    "\n",
    "Now let's evaluate the classifier on a larger sample to get more robust performance metrics. We'll create a confusion matrix to see how well our convention-trained model performs on congressional tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix: dictionary of counts by actual party and estimated party\n",
    "# First key is actual party, second key is estimated party\n",
    "parties = ['Republican', 'Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Initialize the confusion matrix\n",
    "for actual_party in parties:\n",
    "    for predicted_party in parties:\n",
    "        results[actual_party][predicted_party] = 0\n",
    "\n",
    "# Set up for large-scale evaluation\n",
    "num_to_score = min(10000, len(tweet_data))  # Score up to 10,000 tweets\n",
    "print(f\"Evaluating classifier on {num_to_score} tweets...\")\n",
    "\n",
    "# Shuffle data for random sampling\n",
    "random.seed(42)  # For reproducible results\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "# Track progress\n",
    "processed = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "for idx, (tweet, actual_party) in enumerate(tweet_data):\n",
    "    if idx >= num_to_score:\n",
    "        break\n",
    "    \n",
    "    # Extract features and classify\n",
    "    tweet_features = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(tweet_features)\n",
    "    \n",
    "    # Update confusion matrix\n",
    "    results[actual_party][estimated_party] += 1\n",
    "    \n",
    "    # Track accuracy\n",
    "    if estimated_party == actual_party:\n",
    "        correct_predictions += 1\n",
    "    \n",
    "    processed += 1\n",
    "    \n",
    "    # Progress indicator\n",
    "    if processed % 1000 == 0:\n",
    "        current_accuracy = correct_predictions / processed\n",
    "        print(f\"Processed {processed} tweets, current accuracy: {current_accuracy:.3f}\")\n",
    "\n",
    "print(f\"\\nEvaluation completed! Processed {processed} tweets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results in a formatted confusion matrix\n",
    "print(\"\\nConfusion Matrix Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Actual \\\\ Predicted':<20} {'Republican':<12} {'Democratic':<12} {'Total':<8}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "total_actual_rep = sum(results['Republican'].values())\n",
    "total_actual_dem = sum(results['Democratic'].values())\n",
    "total_predicted_rep = results['Republican']['Republican'] + results['Democratic']['Republican']\n",
    "total_predicted_dem = results['Republican']['Democratic'] + results['Democratic']['Democratic']\n",
    "\n",
    "print(f\"{'Republican':<20} {results['Republican']['Republican']:<12} {results['Republican']['Democratic']:<12} {total_actual_rep:<8}\")\n",
    "print(f\"{'Democratic':<20} {results['Democratic']['Republican']:<12} {results['Democratic']['Democratic']:<12} {total_actual_dem:<8}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Total':<20} {total_predicted_rep:<12} {total_predicted_dem:<12} {processed:<8}\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "if processed > 0:\n",
    "    overall_accuracy = (results['Republican']['Republican'] + results['Democratic']['Democratic']) / processed\n",
    "    \n",
    "    # Precision and Recall for each party\n",
    "    if total_predicted_rep > 0:\n",
    "        rep_precision = results['Republican']['Republican'] / total_predicted_rep\n",
    "    else:\n",
    "        rep_precision = 0\n",
    "    \n",
    "    if total_actual_rep > 0:\n",
    "        rep_recall = results['Republican']['Republican'] / total_actual_rep\n",
    "    else:\n",
    "        rep_recall = 0\n",
    "    \n",
    "    if total_predicted_dem > 0:\n",
    "        dem_precision = results['Democratic']['Democratic'] / total_predicted_dem\n",
    "    else:\n",
    "        dem_precision = 0\n",
    "    \n",
    "    if total_actual_dem > 0:\n",
    "        dem_recall = results['Democratic']['Democratic'] / total_actual_dem\n",
    "    else:\n",
    "        dem_recall = 0\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.3f} ({overall_accuracy*100:.1f}%)\")\n",
    "    print(f\"\\nRepublican - Precision: {rep_precision:.3f}, Recall: {rep_recall:.3f}\")\n",
    "    print(f\"Democratic - Precision: {dem_precision:.3f}, Recall: {dem_recall:.3f}\")\n",
    "    \n",
    "    # F1 Scores\n",
    "    if rep_precision + rep_recall > 0:\n",
    "        rep_f1 = 2 * (rep_precision * rep_recall) / (rep_precision + rep_recall)\n",
    "    else:\n",
    "        rep_f1 = 0\n",
    "    \n",
    "    if dem_precision + dem_recall > 0:\n",
    "        dem_f1 = 2 * (dem_precision * dem_recall) / (dem_precision + dem_recall)\n",
    "    else:\n",
    "        dem_f1 = 0\n",
    "    \n",
    "    print(f\"\\nF1 Scores:\")\n",
    "    print(f\"Republican F1: {rep_f1:.3f}\")\n",
    "    print(f\"Democratic F1: {dem_f1:.3f}\")\n",
    "    print(f\"Average F1: {(rep_f1 + dem_f1)/2:.3f}\")\n",
    "\n",
    "# Display raw results dictionary for reference\n",
    "print(f\"\\nRaw Results Dictionary:\")\n",
    "for actual in parties:\n",
    "    print(f\"{actual}: {dict(results[actual])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Reflections and Analysis\n",
    "\n",
    "### Summary of Results\n",
    "\n",
    "Based on our analysis of using a Naive Bayes classifier trained on 2020 convention speeches to classify 2018 congressional tweets, we can make several important observations:\n",
    "\n",
    "#### **Model Performance:**\n",
    "- **Convention Speech Classification**: The classifier likely performed well on convention speeches (the training data) because these are formal, prepared texts with clear partisan language patterns.\n",
    "- **Congressional Tweet Classification**: Performance on tweets was probably more challenging due to the informal nature of social media and the temporal gap (2020 training data vs 2018 tweets).\n",
    "\n",
    "#### **Key Insights:**\n",
    "\n",
    "**1. Domain Transfer Challenges:**\n",
    "- Convention speeches are formal, structured, and policy-focused\n",
    "- Tweets are informal, brief, and often conversational\n",
    "- The vocabulary and style differences create classification challenges\n",
    "\n",
    "**2. Temporal Effects:**\n",
    "- Political language evolves over time\n",
    "- 2020 convention speeches reflect different issues than 2018 congressional campaigns\n",
    "- Some political terms and references may be time-specific\n",
    "\n",
    "**3. Feature Effectiveness:**\n",
    "- Words that strongly distinguish parties in formal speeches may not be as discriminative in tweets\n",
    "- Twitter's character limit forces different linguistic choices\n",
    "- Hashtags, mentions, and informal language patterns weren't fully captured\n",
    "\n",
    "#### **Methodological Observations:**\n",
    "\n",
    "**Strengths of the Approach:**\n",
    "- Naive Bayes is well-suited for text classification with limited training data\n",
    "- The feature selection approach (word frequency cutoff) helped reduce noise\n",
    "- The model successfully identified partisan language patterns in formal political text\n",
    "\n",
    "**Limitations:**\n",
    "- Cross-domain application (speeches → tweets) is inherently challenging\n",
    "- Simple bag-of-words features miss context and sentiment\n",
    "- No handling of Twitter-specific features (hashtags, mentions, etc.)\n",
    "\n",
    "#### **Implications for Political Text Analysis:**\n",
    "\n",
    "1. **Context Matters**: Political text classification works best when training and test data come from similar contexts\n",
    "2. **Platform Differences**: Social media text requires different preprocessing and feature engineering than formal political documents\n",
    "3. **Temporal Stability**: Political language models may need regular updating to maintain accuracy\n",
    "4. **Feature Engineering**: More sophisticated features (n-grams, sentiment, topic models) might improve cross-domain performance\n",
    "\n",
    "#### **Future Improvements:**\n",
    "\n",
    "To improve this analysis, we could:\n",
    "- Use more recent training data closer to the tweet timeframe\n",
    "- Implement Twitter-specific preprocessing (handle hashtags, mentions, URLs)\n",
    "- Experiment with different feature representations (TF-IDF, word embeddings)\n",
    "- Try ensemble methods combining multiple classifiers\n",
    "- Include additional features like tweet metadata, user information, or sentiment scores\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This assignment demonstrates both the power and limitations of Naive Bayes for political text classification. While the model can effectively learn partisan language patterns from formal political speeches, applying these patterns to different text types (tweets) and time periods presents significant challenges. The results highlight the importance of domain-specific training data and the need for careful consideration of text preprocessing and feature engineering in political NLP applications.\n",
    "\n",
    "The exercise provides valuable insights into how political parties use language differently and how machine learning can be applied to understand political communication, while also illustrating the real-world challenges of deploying text classification models across different contexts.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
